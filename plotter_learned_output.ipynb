{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799198a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "font = {'size'   : 22}\n",
    "rc('font', **font)\n",
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "rc('text', usetex=True)\n",
    "plt.rcParams['font.family']='Computer Modern'\n",
    "import scipy.stats as st\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import statistics\n",
    "import os\n",
    "import pandas as pd\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458c5c81",
   "metadata": {},
   "source": [
    "In this Notebook we take the learned output values to compute the Mutual Information and its associated p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a719ec",
   "metadata": {},
   "source": [
    "# Dir definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859f24b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "WPs_dir='training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir='plots/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0366f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_together = np.load('y_RandD.npy')\n",
    "labels_together = np.load('labels_RandD.npy')\n",
    "x_together = np.load('x_RandD.npy')\n",
    "x_together[:,0]=x_together[:,0]#-x_together[:,1]\n",
    "nB = np.sum(labels_together==0.0)\n",
    "print(nB)\n",
    "x_sim = np.load('x_BB1.npy')\n",
    "x_sim[:,0]=x_sim[:,0]#-x_sim[:,1]\n",
    "y_sim = np.load('y_BB1.npy')\n",
    "print(x_sim.shape,y_sim.shape)\n",
    "labels_sim = np.load('labels_BB1.npy')\n",
    "x_sim=x_sim[labels_sim==0.0]\n",
    "y_sim=y_sim[labels_sim==0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fdee82",
   "metadata": {},
   "source": [
    "# WP choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5242a2",
   "metadata": {},
   "source": [
    "We decide which $S/B$ we want to consider and which $\\lambda$s we want to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932290a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas_values = np.load(WPs_dir+'lambda_values.npy')\n",
    "print(lambdas_values)\n",
    "soverbs_vals = np.load(WPs_dir+'soverbs.npy')\n",
    "print(soverbs_vals)\n",
    "soverbs_labels = np.load(WPs_dir+'soverbs_labels.npy')\n",
    "print(soverbs_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19939089",
   "metadata": {},
   "outputs": [],
   "source": [
    "nSoverB = 3\n",
    "SoverB = soverbs_vals[nSoverB]\n",
    "SoverB_label = soverbs_labels[nSoverB]\n",
    "\n",
    "nlambda_val_old = 0#np.argmin(Imeasured[nSoverB])\n",
    "lambda_val_old = lambdas_values[nlambda_val_old]\n",
    "\n",
    "nlambda_val = 1#np.argmin(Imeasured[nSoverB])\n",
    "lambda_val = lambdas_values[nlambda_val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b34f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_values_full = np.load(WPs_dir+'s_values_'+str(nSoverB)+'.npy')\n",
    "s_values_old=s_values_full[nlambda_val_old]\n",
    "s_values=s_values_full[nlambda_val]\n",
    "\n",
    "s_values_sim_full = np.load(WPs_dir+'s_values_sim_'+str(nSoverB)+'.npy')\n",
    "s_values_sim=s_values_sim_full[nlambda_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1f3223",
   "metadata": {},
   "outputs": [],
   "source": [
    "nS = int(SoverB*nB)#np.sum(labels_together==1.0)#\n",
    "print(nB,nS)\n",
    "y_together_bis=y_together[:nB+nS]\n",
    "labels_together_bis=labels_together[:nB+nS]\n",
    "x_together_bis=x_together[:nB+nS]    \n",
    "scaler = StandardScaler()\n",
    "x_together_bis = scaler.fit_transform(x_together_bis)#labels_together.reshape(-1,1)\n",
    "x_sim_bis = scaler.transform(x_sim)\n",
    "minmax = MinMaxScaler()\n",
    "y_together_bis = y_together_bis#minmax.fit_transform(y_together.reshape(-1,1))[:,0]\n",
    "y_sim_bis = y_sim\n",
    "\n",
    "# same as 2009.02205\n",
    "y_low = 3100.0\n",
    "y_high = 3900.0\n",
    "\n",
    "x_together_bis=x_together_bis[y_together_bis>=y_low]\n",
    "labels_together_bis=labels_together_bis[y_together_bis>=y_low]\n",
    "y_together_bis=y_together_bis[y_together_bis>=y_low]\n",
    "\n",
    "x_sim_bis = x_sim_bis[y_sim_bis>=y_low]\n",
    "y_sim_bis = y_sim_bis[y_sim_bis>=y_low]\n",
    "\n",
    "x_together_bis=x_together_bis[y_together_bis<=y_high]\n",
    "labels_together_bis=labels_together_bis[y_together_bis<=y_high]\n",
    "y_together_bis=y_together_bis[y_together_bis<=y_high]\n",
    "\n",
    "x_sim_bis = x_sim_bis[y_sim_bis<=y_high]\n",
    "y_sim_bis = y_sim_bis[y_sim_bis<=y_high]\n",
    "    \n",
    "y_nbins=25\n",
    "y_bins = np.array([np.quantile(y_together_bis,i*1.0/(y_nbins-1)) for i in range(y_nbins) ])\n",
    "    \n",
    "print(np.sum(labels_together_bis)/len(labels_together_bis),len(labels_together_bis))\n",
    "    \n",
    "SR_min = 3300.0#minmax.transform(np.array([3000.0]).reshape(1,-1))\n",
    "SR_max = 3700.0#minmax.transform(np.array([4000.0]).reshape(1,-1))\n",
    "bins_SR = [np.argmin(np.abs(y_bins-SR_min)),np.argmin(np.abs(y_bins-SR_max))]\n",
    "SR = [y_bins[np.argmin(np.abs(y_bins-SR_min))],y_bins[np.argmin(np.abs(y_bins-SR_max))]]\n",
    "SR_min = SR[0]\n",
    "SR_max = SR[1]\n",
    "labels_mixture_together = np.array([1 if a and b else 0 for a,b in zip(y_together_bis>SR[0],y_together_bis<=SR[1])])\n",
    "labels_sim_mixture = np.array([1 if a and b else 0 for a,b in zip(y_sim_bis>SR[0],y_sim_bis<=SR[1])])\n",
    "\n",
    "bins_SR = [np.argmin(np.abs(y_bins-SR_min)),np.argmin(np.abs(y_bins-SR_max))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b9b0a5",
   "metadata": {},
   "source": [
    "# AUC test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1f1e37",
   "metadata": {},
   "source": [
    "We compute the different AUCs to verify that we are forcing CWoLA to ignore the correlations in $x$ and $y$ in the simulated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47a814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_b = labels_together_bis==0.0\n",
    "indexes_m2 = labels_mixture_together==0\n",
    "indexes_s = labels_together_bis==1.0\n",
    "indexes_m1 = labels_mixture_together==1\n",
    "\n",
    "indexes_b_m2 = np.array([a and b for a,b in zip(indexes_b,indexes_m2)])\n",
    "indexes_b_m1 = np.array([a and b for a,b in zip(indexes_b,indexes_m1)])\n",
    "\n",
    "indexes_s_m2 = np.array([a and b for a,b in zip(indexes_s,indexes_m2)])\n",
    "indexes_s_m1 = np.array([a and b for a,b in zip(indexes_s,indexes_m1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0030be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_b_m1_b_m2 = np.zeros(np.sum(indexes_b))\n",
    "nM1 = np.sum(labels_mixture_together[indexes_b]==1.0)\n",
    "nM2 = np.sum(labels_mixture_together[indexes_b]==0.0)\n",
    "list_of_n = np.array([nM1,nM2])\n",
    "min_n = np.min(list_of_n)#[:2])\n",
    "list_of_weights=min_n/list_of_n\n",
    "\n",
    "weights_b_m1_b_m2=np.where(labels_mixture_together[indexes_b]==1.0,list_of_weights[0],list_of_weights[1])\n",
    "\n",
    "auc_b_m1_b_m2 = roc_auc_score(labels_mixture_together[indexes_b],s_values[indexes_b],sample_weight=weights_b_m1_b_m2)\n",
    "auc_b_m1_b_m2_old = roc_auc_score(labels_mixture_together[indexes_b],s_values_old[indexes_b],sample_weight=weights_b_m1_b_m2)\n",
    "print(auc_b_m1_b_m2_old,auc_b_m1_b_m2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99462c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if nS > 0:\n",
    "    weights_s_b = np.zeros(len(labels_together_bis))\n",
    "    nM1 = np.sum(labels_together_bis==1.0)\n",
    "    nM2 = np.sum(labels_together_bis==0.0)\n",
    "    list_of_n = np.array([nM1,nM2])\n",
    "    min_n = np.min(list_of_n)#[:2])\n",
    "    list_of_weights=min_n/list_of_n\n",
    "\n",
    "    weights_s_b=np.where(labels_together_bis==1.0,list_of_weights[0],list_of_weights[1])\n",
    "\n",
    "\n",
    "    auc_s_b = roc_auc_score(labels_together_bis,s_values,sample_weight=weights_s_b)\n",
    "    auc_s_b_old = roc_auc_score(labels_together_bis,s_values_old,sample_weight=weights_s_b)\n",
    "    print(auc_s_b,auc_s_b_old)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba55fb4b",
   "metadata": {},
   "source": [
    "# Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314433c8",
   "metadata": {},
   "source": [
    "First we define the relative statistical uncertainty in each bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d82e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of bins given by uncertainty... assume MC uncertainty where Delta N = sqrt(N), I want sqrt(N)/N = x -> N =(1/x)^2\n",
    "rel_uncertainty = 0.0099\n",
    "s_nbins = round(len(s_values)*rel_uncertainty**2)\n",
    "print(len(s_values)*rel_uncertainty**2,s_nbins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b172b415",
   "metadata": {},
   "source": [
    "Obtain the bins, ensuring each of these have at least $(1/x)^{2}$ events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5929168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some bins may end up empty because I force to split them\n",
    "\n",
    "s_bins_old = np.array([np.quantile(s_values_old,q=i*1.0/(s_nbins-1)) for i in range(s_nbins) ])\n",
    "s_bins = np.array([np.quantile(s_values,i*1.0/(s_nbins-1)) for i in range(s_nbins) ])\n",
    "\n",
    "s_bins = np.unique(s_bins)\n",
    "s_bins_old = np.unique(s_bins_old)\n",
    "print(len(s_bins),len(s_bins_old))\n",
    "\n",
    "\n",
    "s_values_binned, s_bins = np.histogram(s_values,bins=s_bins)\n",
    "s_values_binned_old, s_bins_old = np.histogram(s_values_old,bins=s_bins_old)\n",
    "\n",
    "# merging bins to ensure minimum number of events\n",
    "\n",
    "while np.sum(1.0/np.sqrt(s_values_binned) > rel_uncertainty) > 0:\n",
    "#     print(s_bins)\n",
    "    bins_to_merge = []\n",
    "    nbin = np.where(1.0/np.sqrt(s_values_binned) > rel_uncertainty)[0][0]\n",
    "#     print(nbin)\n",
    "    if nbin == 0:\n",
    "        bins_to_merge=[1]\n",
    "    elif nbin == len(s_values_binned)-1:\n",
    "        bins_to_merge=[len(s_values_binned)-1]\n",
    "    else:\n",
    "        if s_values_binned[nbin-1] < s_values_binned[nbin+1]:\n",
    "            bins_to_merge=[nbin]\n",
    "        else:\n",
    "            bins_to_merge=[nbin+1]\n",
    "    s_bins = np.delete(s_bins,bins_to_merge)\n",
    "    s_values_binned, s_bins = np.histogram(s_values,bins=s_bins)\n",
    "    \n",
    "while np.sum(1.0/np.sqrt(s_values_binned_old) > rel_uncertainty) > 0:\n",
    "#     print(s_bins)\n",
    "    bins_to_merge = []\n",
    "    nbin = np.where(1.0/np.sqrt(s_values_binned_old) > rel_uncertainty)[0][0]\n",
    "#     print(nbin)\n",
    "    if nbin == 0:\n",
    "        bins_to_merge=[1]\n",
    "    elif nbin == len(s_values_binned_old)-1:\n",
    "        bins_to_merge=[len(s_values_binned_old)-1]\n",
    "    else:\n",
    "        if s_values_binned_old[nbin-1] < s_values_binned_old[nbin+1]:\n",
    "            bins_to_merge=[nbin]\n",
    "        else:\n",
    "            bins_to_merge=[nbin+1]\n",
    "    s_bins_old = np.delete(s_bins_old,bins_to_merge)\n",
    "    s_values_binned_old, s_bins_old = np.histogram(s_values_old,bins=s_bins_old)\n",
    "\n",
    "\n",
    "print(len(s_bins),len(s_bins_old))\n",
    "\n",
    "\n",
    "indexes_s = [a and b for a, b in zip(s_values>=s_bins[0],s_values<=s_bins[-1])]\n",
    "indexes_y = [a and b for a, b in zip(y_together_bis>=y_bins[0],y_together_bis<y_bins[-1])]\n",
    "\n",
    "indexes_s_old = [a and b for a, b in zip(s_values_old>=s_bins_old[0],s_values_old<=s_bins_old[-1])]\n",
    "\n",
    "\n",
    "indexes = [ a and b for a,b in zip(indexes_s,indexes_y)]\n",
    "indexes_old = [ a and b for a,b in zip(indexes_s_old,indexes_y)]\n",
    "\n",
    "s_values_filtered = s_values[indexes]\n",
    "s_values_filtered_old = s_values_old[indexes_old]\n",
    "labels_together_filtered = labels_together_bis[indexes]\n",
    "labels_mixture_together_filtered = labels_mixture_together[indexes]\n",
    "y_together_bis_filtered = y_together_bis[indexes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06976c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(s_values,bins=s_bins,histtype='step',color='blue',density=False);\n",
    "plt.hist(s_values_old,bins=s_bins_old,histtype='step',color='blue',linestyle='dashed',density=False);\n",
    "plt.xlabel(r'$s(\\vec{x})$')\n",
    "plt.ylabel(r'Events')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e625daad",
   "metadata": {},
   "source": [
    "Estimate the binned pdfs and with them the Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b300259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pD, bb1, bb2 = np.histogram2d(s_values,y_together_bis,bins=[s_bins,y_bins],density=True)\n",
    "pD_norm = np.array(list(map(lambda indx: list(map(lambda indy: pD[indx,indy]*(s_bins[indx+1]-s_bins[indx])*(y_bins[indy+1]-y_bins[indy]), range(len(y_bins)-1))), range(len(s_bins)-1))))\n",
    "    #             print(np.min(pD_norm),np.sum(pD_norm))\n",
    "pD_marg_s = np.sum(pD_norm,axis=1)\n",
    "pD_marg_s=pD_marg_s/np.sum(pD_marg_s)\n",
    "pD_marg_y = np.sum(pD_norm,axis=0)\n",
    "pD_marg_y=pD_marg_y/np.sum(pD_marg_y)\n",
    "\n",
    "pD_from_marg = np.array(list(map(lambda indx: list(map(lambda indy: pD_marg_s[indx]*pD_marg_y[indy], range(len(y_bins)-1))), range(len(s_bins)-1))))\n",
    "\n",
    "print(np.min(pD_norm),np.min(pD_marg_s),np.min(pD_marg_y))\n",
    "I_measured_new = max([mutual_info(pD_norm,pD_marg_s,pD_marg_y),0.0])\n",
    "print(I_measured_new)\n",
    "\n",
    "pD_old, bb1, bb2 = np.histogram2d(s_values_old,y_together_bis,bins=[s_bins_old,y_bins],density=True)\n",
    "pD_old_norm = np.array(list(map(lambda indx: list(map(lambda indy: pD_old[indx,indy]*(s_bins_old[indx+1]-s_bins_old[indx])*(y_bins[indy+1]-y_bins[indy]), range(len(y_bins)-1))), range(len(s_bins_old)-1))))\n",
    "    #             print(np.min(pD_norm),np.sum(pD_norm))\n",
    "pD_old_marg_s = np.sum(pD_old_norm,axis=1)\n",
    "pD_old_marg_s=pD_old_marg_s/np.sum(pD_old_marg_s)\n",
    "pD_old_marg_y = np.sum(pD_old_norm,axis=0)\n",
    "pD_old_marg_y=pD_old_marg_y/np.sum(pD_old_marg_y)\n",
    "\n",
    "pD_old_from_marg = np.array(list(map(lambda indx: list(map(lambda indy: pD_old_marg_s[indx]*pD_old_marg_y[indy], range(len(y_bins)-1))), range(len(s_bins_old)-1))))\n",
    "\n",
    "print(np.min(pD_old_norm),np.min(pD_old_marg_s),np.min(pD_old_marg_y))\n",
    "I_measured_old = max([mutual_info(pD_old_norm,pD_old_marg_s,pD_old_marg_y),0.0])\n",
    "print(I_measured_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f97bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "significance = np.sum(labels_together_bis)/np.sqrt(np.sum(labels_together_bis==0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745e308a",
   "metadata": {},
   "source": [
    "Asymptotic p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d436c75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asymptotic_distr = st.gamma(a=0.5*(len(s_bins)-2)*(len(y_bins)-2),scale=1.0/(len(s_values_filtered)))\n",
    "print(asymptotic_distr.sf(I_measured_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35d7831",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(st.norm.isf(asymptotic_distr.sf(I_measured_new)))\n",
    "if nS > 0.0:\n",
    "    print(st.norm.isf(asymptotic_distr.sf(I_measured_new))/significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec2f18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "asymptotic_distr_old = st.gamma(a=0.5*(len(s_bins_old)-2)*(len(y_bins)-2),scale=1.0/(len(s_values_filtered_old)))\n",
    "print(asymptotic_distr_old.sf(I_measured_old))\n",
    "print(st.norm.isf(asymptotic_distr_old.sf(I_measured_old)))\n",
    "if nS > 0.0:\n",
    "    print(st.norm.isf(asymptotic_distr_old.sf(I_measured_old))/significance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caad0810",
   "metadata": {},
   "source": [
    "I can do the same for simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2457dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of bins given by uncertainty... assume MC uncertainty where Delta N = sqrt(N), I want sqrt(N)/N = x -> N =(1/x)^2\n",
    "\n",
    "s_nbins_sim = round(len(s_values_sim)*rel_uncertainty**2)\n",
    "print(s_nbins_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some bins may end up empty because I force to split them\n",
    "# s_bins = np.array([0.0]+list(np.linspace(np.quantile(s_values,1*1.0/(s_nbins-1)),np.quantile(s_values,(s_nbins-2)*1.0/(s_nbins-1)),s_nbins))+[1.0])\n",
    "s_bins_sim = np.array([np.quantile(s_values_sim,i*1.0/(s_nbins_sim-1)) for i in range(s_nbins_sim) ])\n",
    "s_bins_sim = np.unique(s_bins_sim)\n",
    "\n",
    "s_values_binned_sim, s_bins_sim = np.histogram(s_values_sim,bins=s_bins_sim)\n",
    "\n",
    "while np.sum(1.0/np.sqrt(s_values_binned_sim) > rel_uncertainty) > 0:\n",
    "#     print(s_bins)\n",
    "    bins_to_merge = []\n",
    "    nbin = np.where(1.0/np.sqrt(s_values_binned_sim) > rel_uncertainty)[0][0]\n",
    "#     print(nbin)\n",
    "    if nbin == 0:\n",
    "        bins_to_merge=[1]\n",
    "    elif nbin == len(s_values_binned_sim)-1:\n",
    "        bins_to_merge=[len(s_values_binned_sim)-1]\n",
    "    else:\n",
    "        if s_values_binned_sim[nbin-1] < s_values_binned_sim[nbin+1]:\n",
    "            bins_to_merge=[nbin]\n",
    "        else:\n",
    "            bins_to_merge=[nbin+1]\n",
    "    s_bins_sim = np.delete(s_bins_sim,bins_to_merge)\n",
    "    s_values_binned_sim, s_bins_sim = np.histogram(s_values_sim,bins=s_bins_sim)\n",
    "    \n",
    "print(len(s_bins_sim))\n",
    "\n",
    "indexes_s = [a and b for a, b in zip(s_values_sim>=s_bins_sim[0],s_values_sim<=s_bins_sim[-1])]\n",
    "indexes_y = [a and b for a, b in zip(y_sim_bis>=y_bins[0],y_sim_bis<y_bins[-1])]\n",
    "\n",
    "indexes = [ a and b for a,b in zip(indexes_s,indexes_y)]\n",
    "\n",
    "s_values_sim_filtered = s_values_sim[indexes]\n",
    "labels_sim_mixture_filtered = labels_sim_mixture[indexes]\n",
    "y_sim_bis_filtered = y_sim_bis[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9018d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pD_sim, bb1, bb2 = np.histogram2d(s_values_sim,y_sim_bis,bins=[s_bins_sim,y_bins],density=True)\n",
    "pD_sim_norm = np.array(list(map(lambda indx: list(map(lambda indy: pD_sim[indx,indy]*(s_bins_sim[indx+1]-s_bins_sim[indx])*(y_bins[indy+1]-y_bins[indy]), range(len(y_bins)-1))), range(len(s_bins_sim)-1))))\n",
    "    #             print(np.min(pD_norm),np.sum(pD_norm))\n",
    "pD_sim_marg_s = np.sum(pD_sim_norm,axis=1)\n",
    "pD_sim_marg_s=pD_sim_marg_s/np.sum(pD_sim_marg_s)\n",
    "pD_sim_marg_y = np.sum(pD_sim_norm,axis=0)\n",
    "pD_sim_marg_y=pD_sim_marg_y/np.sum(pD_sim_marg_y)\n",
    "\n",
    "pD_sim_from_marg = np.array(list(map(lambda indx: list(map(lambda indy: pD_sim_marg_s[indx]*pD_sim_marg_y[indy], range(len(y_bins)-1))), range(len(s_bins_sim)-1))))\n",
    "\n",
    "print(np.min(pD_sim_norm),np.min(pD_sim_marg_s),np.min(pD_sim_marg_y))\n",
    "I_sim_new = max([mutual_info(pD_sim_norm,pD_sim_marg_s,pD_sim_marg_y),0.0])\n",
    "print(I_sim_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e36db",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s_values_sim),len(y_sim_bis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a8f92a",
   "metadata": {},
   "source": [
    "# Plot generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23569d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycolors = [(1., 0.4, 0.0), (0.655728, 0.8, 0.),\n",
    "   (0., 0.742291, 0.873126), (1., 0.656408, 0.), \n",
    "   (0.893126, 0.4, 0.767184), \n",
    "   (0.295048, 0.8, 0.286932), \n",
    "   (0.238758, 0.610466, 1.), (1., 0.325204, 0.406504),\n",
    "    (0., 0.786874, 0.739379), (1., 0.520437, 0.), \n",
    "   (0.7529330319872088, 0.4176501130047967, 1.), \n",
    "   (0.5572809000084149, 0.8, 0), \n",
    "   (1., 0.06811595600706821, 0.0851449450088353), (0, 0.7226017980018511, 0.9321946059944466), \n",
    "   (1., 0.7154761789941944, 0)];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e3bdcd",
   "metadata": {},
   "source": [
    "Plot the output distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e911f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(2*2*4,2*3))\n",
    "\n",
    "ax[0].set_title(r'$S/B$ = '+SoverB_label+', $\\lambda$ = '+str(lambda_val_old))\n",
    "ax[0].hist(s_values_filtered_old[labels_together_filtered==0.0],bins=s_bins_old,histtype='step',color=mycolors[6], linewidth=1.2,alpha=1,label='Background',density=True);\n",
    "ax[0].hist(s_values_filtered_old[labels_mixture_together_filtered==0.0],bins=s_bins_old,histtype='stepfilled',color=mycolors[4],alpha=1,label='$M_{2}$',density=True);\n",
    "ax[0].hist(s_values_filtered_old[labels_mixture_together_filtered==1.0],bins=s_bins_old,histtype='stepfilled',color=mycolors[5],alpha=0.8,label='$M_{1}$',density=True);\n",
    "ax[0].hist(s_values_filtered_old[labels_mixture_together_filtered==0.0],bins=s_bins_old,histtype='step',color=mycolors[4],alpha=1,density=True);\n",
    "if nS > 0.0:\n",
    "    ax[0].hist(s_values_filtered_old[labels_together_filtered==1.0],bins=s_bins_old,histtype='step',color=mycolors[7], linewidth=1.2,alpha=1,label='Signal',density=True);\n",
    "ax[0].set_xlabel(r'$s(\\vec{x})$')\n",
    "ax[0].set_ylabel('PDF')\n",
    "\n",
    "ax[1].set_title(r'$S/B$ = '+SoverB_label+', $\\lambda$ = '+str(lambda_val))\n",
    "ax[1].hist(s_values_filtered[labels_together_filtered==0.0],bins=s_bins,histtype='step',color=mycolors[6],alpha=1, linewidth=1.2,label='Background',density=True);\n",
    "ax[1].hist(s_values_filtered[labels_mixture_together_filtered==0.0],bins=s_bins,histtype='stepfilled',color=mycolors[4],alpha=1,label='$M_{2}$',density=True);\n",
    "ax[1].hist(s_values_filtered[labels_mixture_together_filtered==1.0],bins=s_bins,histtype='stepfilled',color=mycolors[5],alpha=0.8,label='$M_{1}$',density=True);\n",
    "ax[1].hist(s_values_filtered[labels_mixture_together_filtered==0.0],bins=s_bins,histtype='step',color=mycolors[4],alpha=1,density=True);\n",
    "\n",
    "if nS > 0.0:\n",
    "    ax[1].hist(s_values_filtered[labels_together_filtered==1.0],bins=s_bins,histtype='step',color=mycolors[7],alpha=1, linewidth=1.2,label='Signal',density=True);\n",
    "ax[1].set_xlabel(r'$s(\\vec{x})$')\n",
    "ax[1].set_ylabel(r'PDF')\n",
    "\n",
    "ax[0].set_xlim(0,1)\n",
    "ax[0].set_xticks(np.arange(0.0,1.25,0.25))\n",
    "ax[1].set_xticks(np.arange(0.0,1.25,0.25))\n",
    "ax[1].set_xlim(0,1)\n",
    "ax[1].legend(loc='upper right')\n",
    "# ax[0].set_ylim(0,30000)\n",
    "# ax[1].set_ylim(0,30000)\n",
    "ax[0].set_yscale('log')\n",
    "ax[1].set_yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.savefig(results_dir+'new_plot_'+SoverB_label[2:]+'.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9448ba",
   "metadata": {},
   "source": [
    "Run pseudo-experiments and compute the numerical distribution of the MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f65ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nseudo_exp = 10000\n",
    "datasets_from_data_marginals=np.array(list(map(lambda indx: list(map(lambda indy: st.poisson.rvs(mu=(len(s_values))*pD_from_marg[indx,indy],size=Nseudo_exp), range(len(y_bins)-1))), range(len(s_bins)-1))))\n",
    "datasets_from_data_marginals=np.swapaxes(datasets_from_data_marginals,2,1)\n",
    "datasets_from_data_marginals=np.swapaxes(datasets_from_data_marginals,0,1)\n",
    "\n",
    "datasets_from_data_marginals_old=np.array(list(map(lambda indx: list(map(lambda indy: st.poisson.rvs(mu=(len(s_values_old))*pD_old_from_marg[indx,indy],size=Nseudo_exp), range(len(y_bins)-1))), range(len(s_bins_old)-1))))\n",
    "datasets_from_data_marginals_old=np.swapaxes(datasets_from_data_marginals_old,2,1)\n",
    "datasets_from_data_marginals_old=np.swapaxes(datasets_from_data_marginals_old,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3277d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsampled=np.sum(np.sum(datasets_from_data_marginals,axis=2),axis=1)\n",
    "Nsampled_old=np.sum(np.sum(datasets_from_data_marginals_old,axis=2),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0f983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pD_sampled = np.array(list(map(lambda nseudo : datasets_from_data_marginals[nseudo]/Nsampled[nseudo],range(Nseudo_exp))))\n",
    "pD_sampled_old = np.array(list(map(lambda nseudo : datasets_from_data_marginals_old[nseudo]/Nsampled_old[nseudo],range(Nseudo_exp))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad173616",
   "metadata": {},
   "outputs": [],
   "source": [
    "pD_marg_s_sampled = np.sum(pD_sampled,axis=2)\n",
    "pD_marg_y_sampled = np.sum(pD_sampled,axis=1)\n",
    "\n",
    "pD_marg_s_sampled_old = np.sum(pD_sampled_old,axis=2)\n",
    "pD_marg_y_sampled_old = np.sum(pD_sampled_old,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ff607",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info_sampled = np.array(list(map(lambda nseudo : mutual_info(pD_sampled[nseudo],pD_marg_s_sampled[nseudo],pD_marg_y_sampled[nseudo]),range(Nseudo_exp))))\n",
    "mutual_info_sampled_old = np.array(list(map(lambda nseudo : mutual_info(pD_sampled_old[nseudo],pD_marg_s_sampled_old[nseudo],pD_marg_y_sampled_old[nseudo]),range(Nseudo_exp))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6dec30",
   "metadata": {},
   "source": [
    "And now the Mutual Information plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7720432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2.5*4,2.5*3))\n",
    "\n",
    "aa, bb, cc = plt.hist(mutual_info_sampled,density=True,label='Numerical distr.',linestyle='solid',histtype='step',bins=50,color='goldenrod');\n",
    "mi_vals = np.linspace(np.min(mutual_info_sampled),np.max(mutual_info_sampled),100)\n",
    "\n",
    "\n",
    "asymptotic_distr = st.gamma(a=0.5*(len(s_bins)-2)*(len(y_bins)-2),scale=1.0/(len(s_values)))\n",
    "asymptotic=asymptotic_distr.pdf(mi_vals)\n",
    "plt.plot(mi_vals,asymptotic,label=r'$\\mathrm{Gamma}$ distr.',color='black')\n",
    "pval = asymptotic_distr.sf(I_measured_new)\n",
    "significance_new = st.norm.isf(pval)\n",
    "if nS > 0.0:\n",
    "    print(significance_new,significance_new/significance)\n",
    "    label_plot = 'p-value = '+str(round(pval,4))+',\\n'+r'$Z/Z_{0}$ = '+str(round(significance_new/significance,3))\n",
    "else:\n",
    "    label_plot = 'p-value = '+str(round(pval,4))\n",
    "if I_measured_new <= mi_vals[-1]:\n",
    "    plt.axvline(I_measured_new,label=r'$\\hat{I}_{\\mathrm{data}}$ = '+str(round(I_measured_new,5)),color='blue')\n",
    "    plt.fill_between(y1=asymptotic[mi_vals>=I_measured_new],x=mi_vals[mi_vals>=I_measured_new],color='red',alpha=0.25,label=label_plot)\n",
    "else:\n",
    "    plt.axvline(I_measured_new,label=r'$\\hat{I}_{\\mathrm{data}}$ = '+str(round(I_measured_new,5)),color='blue')\n",
    "    plt.fill_between(y1=asymptotic[mi_vals>=I_measured_new],x=mi_vals[mi_vals>=I_measured_new],color='red',alpha=0.25,label=label_plot)\n",
    "    plt.xlim((np.min(mutual_info_sampled),np.max(mutual_info_sampled)))\n",
    "\n",
    "plt.legend(loc='upper right',framealpha=0.75,fontsize=24)\n",
    "plt.xlabel(r'$\\hat{I}(s(\\vec{x}),m_{jj})$')\n",
    "plt.ylabel('PDF')\n",
    "plt.ylim(0.0)\n",
    "plt.xticks(np.arange(0.0006,0.001,0.0001))\n",
    "\n",
    "plt.title(r'$S/B$ = '+SoverB_label)#+r', $\\lambda$ = '+str(lambda_val))#,'+'\\n'+r'$\\hat{I}(s(\\vec{x}),m_{jj})$ = '+str(round(I_measured_new,5))+', p-value = '+str(round(pval,6)))\n",
    "plt.tight_layout()\n",
    "plt.savefig(results_dir+'mutual_information_'+SoverB_label[2:]+'.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d57966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
